{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34UYQDnMOyEt"
   },
   "source": [
    "# MNIST Classifier from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "deklZSSdOw8H",
    "outputId": "f52f97a5-fb42-477a-8f7d-9f65757d233e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hMounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "! [ -e /content ] && pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "o-3mUnRLPGEJ"
   },
   "outputs": [],
   "source": [
    "import fastbook\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vYEC0q5PK14"
   },
   "source": [
    "## The MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FedHvZzLIdc8"
   },
   "source": [
    "First, we import the full MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "jOB9CdTnPJTF",
    "outputId": "7969864d-e298-4c21-dc7e-1edcce504c3f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yx_K9iWVPY9c",
    "outputId": "d3fd08a2-ce70-4f88-f460-fd738c7a5aa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Path('training'), Path('testing')] [Path('training/4'), Path('training/3'), Path('training/5'), Path('training/1'), Path('training/7'), Path('training/6'), Path('training/8'), Path('training/0'), Path('training/9'), Path('training/2')]\n"
     ]
    }
   ],
   "source": [
    "print(path.ls(), (path/'training').ls())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gx8CrNrEIiHg"
   },
   "source": [
    "Now we want to create a tensor from each image in the dataset, and have them all appropiately labeled. For that reason, we'll create a dictionary and assign each number as a key to a list of the tensors of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GSHP0QMUPc3F"
   },
   "outputs": [],
   "source": [
    "digits = {}\n",
    "for i in range(10):\n",
    "  digits[i] = (path/'training'/str(i)).ls().sorted()\n",
    "\n",
    "tensors = [[tensor(Image.open(o)) for o in digits[i]] for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 45
    },
    "id": "on0snT9qQScp",
    "outputId": "ee497a32-0dad-40c3-f736-f54da2512c4a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/UlEQVR4nGNgGHBQ9v9VEC65yB///n5Jwy7Hdv7vmp1/52KXnPT3m4jC20/y2OREnv1tZGC4+bcDm+SZf5+kGBgW/FsME2BCyAkof099xsDw6f9rLBrD/q5mYGBguPnLDovkyr/mDAwMLHewaWT491eFgYEh/O9KuAjCTmnGDXcYGBisGJ9jkXT4383AwMAg/P8sFlNX/BNiYGDI+XWBA4ukejkLA4Peq78V2NzDwMDAwH7+31ZuHHL22//918EqI7L69a+/f/993meMKWf37N/fvw+m19/6+7aSD10y/e+/nxt4GBh4Jvz8u5wJTZKtI9MSwnI41MGKy8W0BwB/KFowANCH2QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img0_path = digits[2][1040]\n",
    "im0 = Image.open(img0_path)\n",
    "im0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsGw575zI4Hq"
   },
   "source": [
    "Some validations!\n",
    "- Of the size of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTD_TZbqQa6q",
    "outputId": "844ff1d0-30b7-40e1-ff22-29dbfd2e7d9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  5923\n",
      "1:  6742\n",
      "2:  5958\n",
      "3:  6131\n",
      "4:  5842\n",
      "5:  5421\n",
      "6:  5918\n",
      "7:  6265\n",
      "8:  5851\n",
      "9:  5949\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "  print('{}: '.format(i), len(tensors[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-UzxC4qI_96"
   },
   "source": [
    "- Of the shape of each tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zl0zRbo_Sa4X",
    "outputId": "dc6c42f8-1327-43ae-ce97-aa6d77b66c48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors[3][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrADOsXMJJLP"
   },
   "source": [
    "Now we want to stack each class into a rank-3 tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMrZrn5_To7h",
    "outputId": "bda30658-c214-492d-a17e-9a0ec44d9a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  torch.Size([5923, 28, 28])\n",
      "1:  torch.Size([6742, 28, 28])\n",
      "2:  torch.Size([5958, 28, 28])\n",
      "3:  torch.Size([6131, 28, 28])\n",
      "4:  torch.Size([5842, 28, 28])\n",
      "5:  torch.Size([5421, 28, 28])\n",
      "6:  torch.Size([5918, 28, 28])\n",
      "7:  torch.Size([6265, 28, 28])\n",
      "8:  torch.Size([5851, 28, 28])\n",
      "9:  torch.Size([5949, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "stacked = [torch.stack(tensors[i]).float()/255 for i in range(10)]\n",
    "for i in range(10):\n",
    "  print('{}: '.format(i), stacked[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hlDQgO0YcTy",
    "outputId": "84eefeb4-2283-4865-e529-26b35905a144"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_0:  torch.Size([980, 28, 28])\n",
      "valid_1:  torch.Size([1135, 28, 28])\n",
      "valid_2:  torch.Size([1032, 28, 28])\n",
      "valid_3:  torch.Size([1010, 28, 28])\n",
      "valid_4:  torch.Size([982, 28, 28])\n",
      "valid_5:  torch.Size([892, 28, 28])\n",
      "valid_6:  torch.Size([958, 28, 28])\n",
      "valid_7:  torch.Size([1028, 28, 28])\n",
      "valid_8:  torch.Size([974, 28, 28])\n",
      "valid_9:  torch.Size([1009, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "valid_digits = {}\n",
    "for i in range(10):\n",
    "  valid_digits[i] = (path/'testing'/str(i)).ls().sorted()\n",
    "\n",
    "valid_tensors = [[tensor(Image.open(o)) for o in valid_digits[i]] for i in range(10)]\n",
    "valid_stacked = [torch.stack(valid_tensors[i]).float()/255 for i in range(10)]\n",
    "\n",
    "for i in range(10):\n",
    "  print('valid_{}: '.format(i), valid_stacked[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5Tgj8SFJRIn"
   },
   "source": [
    "Finally, for the training set, we want to create a single rank-2 tensor containing all classes stacked and every image transformed to a vector. For the validating set, we want a hot-encoded vector for each integer the image represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QyuBR2hFYeCm",
    "outputId": "dd455531-7953-4f00-d480-e76d04466b2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([60000, 10]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = torch.cat([stacked[i] for i in range(10)]).view(-1,28*28)\n",
    "train_y = []\n",
    "for i in range(10):\n",
    "    zeros = [0]*tensor(10)\n",
    "    zeros[i] = 1.\n",
    "    train_y += zeros * len(digits[i])\n",
    "train_y = tensor(train_y).view((-1,10))\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LCGBHpkEcGrF"
   },
   "outputs": [],
   "source": [
    "dset = list(zip(train_x, train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYGSZEllMIzY"
   },
   "source": [
    "Doing the same for the vaildation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzAxNoeSdS8A",
    "outputId": "dd74cfa4-0e46-444e-f271-5615efe43ff6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 784]), torch.Size([10000, 10]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x = torch.cat([valid_stacked[i] for i in range(10)]).view(-1,28*28)\n",
    "valid_y = []\n",
    "for i in range(10):\n",
    "    zeros = [0]*tensor(10)\n",
    "    zeros[i] = 1.\n",
    "    valid_y += zeros * len(valid_digits[i])\n",
    "valid_y = tensor(valid_y).view((-1,10))\n",
    "valid_x.shape, valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q9QUnp3Ye5Dh",
    "outputId": "32ff2478-0abe-49c8-a58c-ddcc13b82ebe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = dset[9]; x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DC3uclXzfCXg"
   },
   "outputs": [],
   "source": [
    "valid_dset = list(zip(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Za_eNBZi9UPb"
   },
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8znBBBd1-qwN"
   },
   "outputs": [],
   "source": [
    "def init_params(size, std=1): return (torch.randn(size)*std).requires_grad_()\n",
    "weights = init_params((28*28,10))\n",
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Muf4j7uHuez",
    "outputId": "adcc8922-0125-4101-c24c-00e50618935d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.6670e-12, 6.0144e-08, 1.9665e-04,  ..., 5.9243e-07, 1.1039e-06, 9.9382e-01],\n",
       "        [3.3582e-09, 1.7959e-07, 2.8649e-05,  ..., 1.0690e-09, 3.9134e-05, 1.0747e-01],\n",
       "        [6.2731e-22, 2.6699e-10, 8.1824e-07,  ..., 2.4047e-12, 9.5857e-01, 4.1432e-02],\n",
       "        ...,\n",
       "        [1.2629e-13, 7.4681e-04, 2.9012e-04,  ..., 3.5388e-05, 6.4642e-02, 9.3425e-01],\n",
       "        [3.0635e-14, 6.9778e-09, 6.0548e-07,  ..., 6.8531e-07, 9.9697e-01, 2.1861e-03],\n",
       "        [1.1982e-10, 5.9056e-03, 7.6727e-03,  ..., 7.2289e-01, 1.4260e-03, 2.4199e-01]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear1(xb): return F.softmax(xb@weights + bias, dim=1)\n",
    "preds = linear1(train_x)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HQDXdwpz2_sD"
   },
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "  predictions = predictions.softmax(1)\n",
    "  return torch.where(targets==1,1-predictions,predictions).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RL-Cbgip9ji9",
    "outputId": "fe3a34db-872c-47e8-9ed0-a69a8ddc55c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 10]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "xb, yb = first(dl)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5lj_FzT39kXs"
   },
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_dset, batch_size = 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptXWcIa-dEZl"
   },
   "source": [
    "### Sidebar: Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vsrW_L-5P1v4",
    "outputId": "c1c5cc08-d1d0-4692-c0f9-185341a3a9cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 784])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "## Creating a mini-batch of size 5 for testing\n",
    "batch = train_x[:5]\n",
    "batch.shape # Outputs torch.Size([5, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HyQlWo-WdLQP",
    "outputId": "76339a2a-6575-44c6-8bbd-671f5d70baaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1827, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = linear1(batch)\n",
    "loss = mnist_loss(preds, train_y[:5])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RnvXroXRdTUk",
    "outputId": "ffe4e6ee-f16d-4d85-cb22-a0189fa64a15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 10]), tensor(-3.3558e-12), tensor([-2.1100e-10]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the gradients\n",
    "loss.backward()\n",
    "weights.grad.shape,weights.grad.mean(),bias.grad # Outputs (torch.Size([784, 1]), tensor(-0.0001), tensor([-0.0008]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VttsVSVkdH9J"
   },
   "source": [
    "### End sidebar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ZO6Apmc-QB2K"
   },
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "  preds = model(xb)\n",
    "  loss = mnist_loss(preds, yb)\n",
    "  loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "2GXvtLViQjNF"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, params):\n",
    "  for xb,yb in dl:\n",
    "    calc_grad(xb, yb, model)\n",
    "    for p in params:\n",
    "      p.data -= p.grad*lr \n",
    "      p.grad.zero_()\n",
    "\n",
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.argmax(dim=1)\n",
    "    true_classes = yb.argmax(dim=1)\n",
    "    # correct = preds == yb.squeeze()\n",
    "    # return correct.float().mean()\n",
    "    correct = (preds == true_classes).sum().item()\n",
    "    total = xb.size(0)\n",
    "    return tensor(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k145rs-hWA58",
    "outputId": "06b6192b-e2b2-4cad-d146-b2c928536568"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy(linear1(batch), train_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Arsi8MQeWE_i"
   },
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "  accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
    "  return round(torch.stack(accs).mean().item(),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g6fH8ivNWefu",
    "outputId": "c133a8ac-d74b-4ee1-fb15-409822513310"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1253"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7g9PpvMoWgVV",
    "outputId": "7c640ac0-52ca-4beb-ef6d-e389439f27ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.validate_epoch(model)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1.\n",
    "params = weights,bias\n",
    "train_epoch(linear1, lr, params)\n",
    "validate_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lbJgoKYNWsJR",
    "outputId": "d53ea436-1b29-4180-9497-c40a266ed7e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1467 0.1561 0.1688 0.1811 0.1923 0.2051 0.2201 0.2297 0.2393 0.2501 0.2602 0.2716 0.2823 0.2925 0.3037 0.3123 0.3205 0.3284 0.3359 0.3418 "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "  train_epoch(linear1, lr, params)\n",
    "  print(validate_epoch(linear1), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXKTnDqbqdYD"
   },
   "source": [
    "## Creating an Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xVCLaRtXW5L8",
    "outputId": "d8a0adc8-a51a-4019-8a8e-18923b9691f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 784]), torch.Size([10]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28,10)\n",
    "w,b = linear_model.parameters()\n",
    "w.shape,b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "_U8By3RxqpwW"
   },
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "  def __init__(self,params,lr): self.params,self.lr = list(params), lr\n",
    "  \n",
    "  def step(self, *args, **kwargs):\n",
    "    for p in self.params: p.data -= p.grad.data * self.lr\n",
    "\n",
    "  def zero_grad(self, *args, **kwargs):\n",
    "    for p in self.params: p.grad = None\n",
    "\n",
    "opt = BasicOptim(linear_model.parameters(), lr)\n",
    "\n",
    "def train_epoch(model):\n",
    "  for xb,yb in dl:\n",
    "    calc_grad(xb,yb,model)\n",
    "    opt.step()\n",
    "    opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8J58OcNOrXKL",
    "outputId": "2260cb2f-562d-4708-bd29-38a6fd2410a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.065"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "KgQJjvQhrhT1"
   },
   "outputs": [],
   "source": [
    "def train_model(model, epochs):\n",
    "  for i in range(epochs):\n",
    "    train_epoch(model)\n",
    "    print(validate_epoch(model), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_FXiMVcsf6K"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rV7s3p_irpB5",
    "outputId": "0de6fe0f-5827-48ae-a8b3-63d872d1edc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2261 0.2646 0.3722 0.4772 0.488 0.5294 0.5718 0.478 0.4441 0.4836 0.5183 0.5476 0.572 0.5912 0.6075 0.622 0.6334 0.6443 0.6554 0.6662 "
     ]
    }
   ],
   "source": [
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "XCjjs2xprrMX"
   },
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl, valid_dl)\n",
    "learn = Learner(dls, nn.Linear(28*28,10), opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "w3uHoo0WtXvZ",
    "outputId": "c7102f18-ae13-47d0-ac77-3c7b001a525d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.180068</td>\n",
       "      <td>0.161426</td>\n",
       "      <td>0.197600</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.152673</td>\n",
       "      <td>0.141732</td>\n",
       "      <td>0.322100</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.143203</td>\n",
       "      <td>0.127619</td>\n",
       "      <td>0.384800</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.137055</td>\n",
       "      <td>0.115690</td>\n",
       "      <td>0.459600</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.131596</td>\n",
       "      <td>0.106320</td>\n",
       "      <td>0.503500</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.130316</td>\n",
       "      <td>0.098618</td>\n",
       "      <td>0.542700</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.129861</td>\n",
       "      <td>0.092294</td>\n",
       "      <td>0.579200</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.129627</td>\n",
       "      <td>0.086995</td>\n",
       "      <td>0.603200</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.129475</td>\n",
       "      <td>0.082605</td>\n",
       "      <td>0.624700</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.129364</td>\n",
       "      <td>0.078952</td>\n",
       "      <td>0.644600</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.129277</td>\n",
       "      <td>0.075892</td>\n",
       "      <td>0.658400</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.129203</td>\n",
       "      <td>0.073308</td>\n",
       "      <td>0.667700</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.129135</td>\n",
       "      <td>0.071112</td>\n",
       "      <td>0.678200</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.129072</td>\n",
       "      <td>0.069232</td>\n",
       "      <td>0.687600</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.129012</td>\n",
       "      <td>0.067612</td>\n",
       "      <td>0.694000</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.128955</td>\n",
       "      <td>0.066206</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.128900</td>\n",
       "      <td>0.064978</td>\n",
       "      <td>0.705700</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.128848</td>\n",
       "      <td>0.063899</td>\n",
       "      <td>0.709300</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.128799</td>\n",
       "      <td>0.062944</td>\n",
       "      <td>0.712900</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.128752</td>\n",
       "      <td>0.062094</td>\n",
       "      <td>0.716600</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(20,lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFgRZcvJJzsn"
   },
   "source": [
    "## Adding a non-linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "eCGAEL7-te1-"
   },
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "SGzcVWhVa4fj"
   },
   "outputs": [],
   "source": [
    "learn = Learner(dls, simple_net, opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_VJD8YFKbDf-",
    "outputId": "c2edb29f-de59-4b16-fabb-fbfa9684c4eb",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.181002</td>\n",
       "      <td>0.177281</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.178668</td>\n",
       "      <td>0.171460</td>\n",
       "      <td>0.373900</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.173569</td>\n",
       "      <td>0.161231</td>\n",
       "      <td>0.394700</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.156330</td>\n",
       "      <td>0.151298</td>\n",
       "      <td>0.331300</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.128234</td>\n",
       "      <td>0.145241</td>\n",
       "      <td>0.327900</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.117303</td>\n",
       "      <td>0.133916</td>\n",
       "      <td>0.384400</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.107615</td>\n",
       "      <td>0.124814</td>\n",
       "      <td>0.418500</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.099337</td>\n",
       "      <td>0.117569</td>\n",
       "      <td>0.446700</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.094120</td>\n",
       "      <td>0.111720</td>\n",
       "      <td>0.476100</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.090793</td>\n",
       "      <td>0.107077</td>\n",
       "      <td>0.497700</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.088603</td>\n",
       "      <td>0.103439</td>\n",
       "      <td>0.514800</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.087241</td>\n",
       "      <td>0.100645</td>\n",
       "      <td>0.528000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.087267</td>\n",
       "      <td>0.098680</td>\n",
       "      <td>0.532500</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.091038</td>\n",
       "      <td>0.095993</td>\n",
       "      <td>0.554800</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.088415</td>\n",
       "      <td>0.091948</td>\n",
       "      <td>0.588000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.087592</td>\n",
       "      <td>0.604500</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.085699</td>\n",
       "      <td>0.084395</td>\n",
       "      <td>0.615100</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.084511</td>\n",
       "      <td>0.082053</td>\n",
       "      <td>0.622300</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.083436</td>\n",
       "      <td>0.080187</td>\n",
       "      <td>0.627900</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.082438</td>\n",
       "      <td>0.078571</td>\n",
       "      <td>0.632700</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.081500</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.637400</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.080622</td>\n",
       "      <td>0.075718</td>\n",
       "      <td>0.642100</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.079795</td>\n",
       "      <td>0.074408</td>\n",
       "      <td>0.648300</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.079029</td>\n",
       "      <td>0.073147</td>\n",
       "      <td>0.653100</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.078315</td>\n",
       "      <td>0.071944</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.077662</td>\n",
       "      <td>0.070785</td>\n",
       "      <td>0.663200</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.077059</td>\n",
       "      <td>0.069674</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.076510</td>\n",
       "      <td>0.068612</td>\n",
       "      <td>0.674200</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.076008</td>\n",
       "      <td>0.067599</td>\n",
       "      <td>0.680300</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.075549</td>\n",
       "      <td>0.066639</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.075125</td>\n",
       "      <td>0.065735</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.074739</td>\n",
       "      <td>0.064881</td>\n",
       "      <td>0.693600</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.074387</td>\n",
       "      <td>0.064070</td>\n",
       "      <td>0.698800</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.074065</td>\n",
       "      <td>0.063311</td>\n",
       "      <td>0.702400</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.073770</td>\n",
       "      <td>0.062596</td>\n",
       "      <td>0.706500</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.061921</td>\n",
       "      <td>0.709100</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.073254</td>\n",
       "      <td>0.061287</td>\n",
       "      <td>0.711400</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.073027</td>\n",
       "      <td>0.060691</td>\n",
       "      <td>0.715200</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.072819</td>\n",
       "      <td>0.060133</td>\n",
       "      <td>0.717900</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.072626</td>\n",
       "      <td>0.059608</td>\n",
       "      <td>0.721200</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(40,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-FQ5yVx1bFKl",
    "outputId": "81eba72f-7901-4b3f-e386-d2c56e887dfd"
   },
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_folder(path, train='training', valid='testing', device='mps')\n",
    "learn = vision_learner(dls, resnet18, pretrained=False, loss_func=F.cross_entropy, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 94
    },
    "id": "G5wbzLrobdhM",
    "outputId": "3c7408fc-f2f8-4495-d692-bb9b26598820",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.095913</td>\n",
       "      <td>0.039997</td>\n",
       "      <td>0.987200</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9caLwzWOckG2",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
