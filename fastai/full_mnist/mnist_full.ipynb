{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34UYQDnMOyEt"
   },
   "source": [
    "# MNIST Classifier from scratch\n",
    "\n",
    "This is part of the Further Research section in the Chapter 4 of the fastai book. It consists of building a full MNIST Classifier from scratch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "deklZSSdOw8H",
    "outputId": "f52f97a5-fb42-477a-8f7d-9f65757d233e"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "# Google Colab Setup\n",
    "! [ -e /content ] && pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "o-3mUnRLPGEJ"
   },
   "outputs": [],
   "source": [
    "import fastbook\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vYEC0q5PK14"
   },
   "source": [
    "## The MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FedHvZzLIdc8"
   },
   "source": [
    "First, we import the full MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "jOB9CdTnPJTF",
    "outputId": "7969864d-e298-4c21-dc7e-1edcce504c3f"
   },
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yx_K9iWVPY9c",
    "outputId": "d3fd08a2-ce70-4f88-f460-fd738c7a5aa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Path('training'), Path('testing')] [Path('training/9'), Path('training/0'), Path('training/7'), Path('training/6'), Path('training/1'), Path('training/8'), Path('training/4'), Path('training/3'), Path('training/2'), Path('training/5')]\n"
     ]
    }
   ],
   "source": [
    "print(path.ls(), (path/'training').ls())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gx8CrNrEIiHg"
   },
   "source": [
    "Now we want to create a tensor from each image in the dataset, and have them all appropiately labeled. For that reason, we'll create a dictionary and assign each number as a key to a list of the tensors of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "GSHP0QMUPc3F"
   },
   "outputs": [],
   "source": [
    "digits = {}\n",
    "for i in range(10):\n",
    "  digits[i] = (path/'training'/str(i)).ls().sorted()\n",
    "\n",
    "tensors = [[tensor(Image.open(o)) for o in digits[i]] for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Validations!\n",
    "- Of the images we indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 45
    },
    "id": "on0snT9qQScp",
    "outputId": "ee497a32-0dad-40c3-f736-f54da2512c4a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/UlEQVR4nGNgGHBQ9v9VEC65yB///n5Jwy7Hdv7vmp1/52KXnPT3m4jC20/y2OREnv1tZGC4+bcDm+SZf5+kGBgW/FsME2BCyAkof099xsDw6f9rLBrD/q5mYGBguPnLDovkyr/mDAwMLHewaWT491eFgYEh/O9KuAjCTmnGDXcYGBisGJ9jkXT4383AwMAg/P8sFlNX/BNiYGDI+XWBA4ukejkLA4Peq78V2NzDwMDAwH7+31ZuHHL22//918EqI7L69a+/f/993meMKWf37N/fvw+m19/6+7aSD10y/e+/nxt4GBh4Jvz8u5wJTZKtI9MSwnI41MGKy8W0BwB/KFowANCH2QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img0_path = digits[2][1040]\n",
    "im0 = Image.open(img0_path)\n",
    "im0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsGw575zI4Hq"
   },
   "source": [
    "- Of the size of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTD_TZbqQa6q",
    "outputId": "844ff1d0-30b7-40e1-ff22-29dbfd2e7d9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  5923\n",
      "1:  6742\n",
      "2:  5958\n",
      "3:  6131\n",
      "4:  5842\n",
      "5:  5421\n",
      "6:  5918\n",
      "7:  6265\n",
      "8:  5851\n",
      "9:  5949\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "  print('{}: '.format(i), len(tensors[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-UzxC4qI_96"
   },
   "source": [
    "- Of the shape of each tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zl0zRbo_Sa4X",
    "outputId": "dc6c42f8-1327-43ae-ce97-aa6d77b66c48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors[3][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrADOsXMJJLP"
   },
   "source": [
    "Now we want to stack each class into a rank-3 tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMrZrn5_To7h",
    "outputId": "bda30658-c214-492d-a17e-9a0ec44d9a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  torch.Size([5923, 28, 28])\n",
      "1:  torch.Size([6742, 28, 28])\n",
      "2:  torch.Size([5958, 28, 28])\n",
      "3:  torch.Size([6131, 28, 28])\n",
      "4:  torch.Size([5842, 28, 28])\n",
      "5:  torch.Size([5421, 28, 28])\n",
      "6:  torch.Size([5918, 28, 28])\n",
      "7:  torch.Size([6265, 28, 28])\n",
      "8:  torch.Size([5851, 28, 28])\n",
      "9:  torch.Size([5949, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "stacked = [torch.stack(tensors[i]).float()/255 for i in range(10)]\n",
    "for i in range(10):\n",
    "  print('{}: '.format(i), stacked[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hlDQgO0YcTy",
    "outputId": "84eefeb4-2283-4865-e529-26b35905a144"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_0:  torch.Size([980, 28, 28])\n",
      "valid_1:  torch.Size([1135, 28, 28])\n",
      "valid_2:  torch.Size([1032, 28, 28])\n",
      "valid_3:  torch.Size([1010, 28, 28])\n",
      "valid_4:  torch.Size([982, 28, 28])\n",
      "valid_5:  torch.Size([892, 28, 28])\n",
      "valid_6:  torch.Size([958, 28, 28])\n",
      "valid_7:  torch.Size([1028, 28, 28])\n",
      "valid_8:  torch.Size([974, 28, 28])\n",
      "valid_9:  torch.Size([1009, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "valid_digits = {}\n",
    "for i in range(10):\n",
    "  valid_digits[i] = (path/'testing'/str(i)).ls().sorted()\n",
    "\n",
    "valid_tensors = [[tensor(Image.open(o)) for o in valid_digits[i]] for i in range(10)]\n",
    "valid_stacked = [torch.stack(valid_tensors[i]).float()/255 for i in range(10)]\n",
    "\n",
    "for i in range(10):\n",
    "  print('valid_{}: '.format(i), valid_stacked[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5Tgj8SFJRIn"
   },
   "source": [
    "Finally, for our `x` inputs, we want to create a single rank-2 tensor containing all classes stacked and every image transformed to a vector. For the `y` targets, we want a hot-encoded vector for each integer the image represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QyuBR2hFYeCm",
    "outputId": "dd455531-7953-4f00-d480-e76d04466b2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([60000, 10]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = torch.cat([stacked[i] for i in range(10)]).view(-1,28*28)\n",
    "train_y = []\n",
    "for i in range(10):\n",
    "    zeros = [0]*tensor(10)\n",
    "    zeros[i] = 1.\n",
    "    train_y += zeros * len(digits[i])\n",
    "train_y = tensor(train_y).view((-1,10))\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "LCGBHpkEcGrF"
   },
   "outputs": [],
   "source": [
    "dset = list(zip(train_x, train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYGSZEllMIzY"
   },
   "source": [
    "Doing the same for the vaildation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzAxNoeSdS8A",
    "outputId": "dd74cfa4-0e46-444e-f271-5615efe43ff6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 784]), torch.Size([10000, 10]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x = torch.cat([valid_stacked[i] for i in range(10)]).view(-1,28*28)\n",
    "valid_y = []\n",
    "for i in range(10):\n",
    "    zeros = [0]*tensor(10)\n",
    "    zeros[i] = 1.\n",
    "    valid_y += zeros * len(valid_digits[i])\n",
    "valid_y = tensor(valid_y).view((-1,10))\n",
    "valid_x.shape, valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q9QUnp3Ye5Dh",
    "outputId": "32ff2478-0abe-49c8-a58c-ddcc13b82ebe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = dset[9]; x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "DC3uclXzfCXg"
   },
   "outputs": [],
   "source": [
    "valid_dset = list(zip(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Za_eNBZi9UPb"
   },
   "source": [
    "## Loss function\n",
    "\n",
    "First, we define a function to initialize our parameters. It is important to remember we have 10 classes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "8znBBBd1-qwN"
   },
   "outputs": [],
   "source": [
    "def init_params(size, std=1): return (torch.randn(size)*std).requires_grad_()\n",
    "weights = init_params((28*28,10))\n",
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to build a libear function for our predictions. We are using a softmax function, since we want our predictions to output a probability for each one of the 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Muf4j7uHuez",
    "outputId": "adcc8922-0125-4101-c24c-00e50618935d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7995e-07, 4.1746e-16, 6.6198e-08,  ..., 4.7592e-17, 3.4086e-05, 9.5948e-14],\n",
       "        [4.6760e-10, 7.4733e-15, 3.9889e-16,  ..., 9.7262e-16, 2.8436e-10, 2.4661e-11],\n",
       "        [1.2541e-18, 9.8313e-26, 2.3247e-14,  ..., 9.7353e-26, 7.0008e-08, 3.5697e-21],\n",
       "        ...,\n",
       "        [1.6117e-12, 1.0476e-11, 9.3556e-07,  ..., 2.5763e-08, 6.4884e-06, 1.5282e-04],\n",
       "        [1.3881e-11, 8.2489e-09, 2.4626e-11,  ..., 5.8326e-06, 2.7856e-11, 1.1645e-09],\n",
       "        [2.0035e-10, 9.7288e-12, 1.2878e-11,  ..., 3.5700e-09, 8.0692e-05, 1.6643e-05]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear1(xb): return F.softmax(xb@weights + bias, dim=1)\n",
    "preds = linear1(train_x)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "HQDXdwpz2_sD"
   },
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "  predictions = predictions.softmax(1)\n",
    "  return torch.where(targets==1,1-predictions,predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And define our `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RL-Cbgip9ji9",
    "outputId": "fe3a34db-872c-47e8-9ed0-a69a8ddc55c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 10]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "valid_dl = DataLoader(valid_dset, batch_size = 256)\n",
    "xb, yb = first(dl)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptXWcIa-dEZl"
   },
   "source": [
    "### Sidebar: Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vsrW_L-5P1v4",
    "outputId": "c1c5cc08-d1d0-4692-c0f9-185341a3a9cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 784])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "## Creating a mini-batch of size 5 for testing\n",
    "batch = train_x[:5]\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HyQlWo-WdLQP",
    "outputId": "76339a2a-6575-44c6-8bbd-671f5d70baaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1829, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = linear1(batch)\n",
    "loss = mnist_loss(preds, train_y[:5])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RnvXroXRdTUk",
    "outputId": "ffe4e6ee-f16d-4d85-cb22-a0189fa64a15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 10]), tensor(4.1818e-12), tensor([2.2697e-10]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the gradients\n",
    "loss.backward()\n",
    "weights.grad.shape,weights.grad.mean(),bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VttsVSVkdH9J"
   },
   "source": [
    "### End sidebar\n",
    "\n",
    "Now we define a function that calculates the gradients of our parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "ZO6Apmc-QB2K"
   },
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "  preds = model(xb)\n",
    "  loss = mnist_loss(preds, yb)\n",
    "  loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a function to train each epoch, and one to calculate the accuracy for each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "2GXvtLViQjNF"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, params):\n",
    "  for xb,yb in dl:\n",
    "    calc_grad(xb, yb, model)\n",
    "    for p in params:\n",
    "      p.data -= p.grad*lr \n",
    "      p.grad.zero_()\n",
    "\n",
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.argmax(dim=1)\n",
    "    true_classes = yb.argmax(dim=1)\n",
    "    correct = (preds == true_classes).sum().item()\n",
    "    total = xb.size(0)\n",
    "    return tensor(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k145rs-hWA58",
    "outputId": "06b6192b-e2b2-4cad-d146-b2c928536568"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making sure it works\n",
    "batch_accuracy(linear1(batch), train_y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a function to calculate the accuracy for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Arsi8MQeWE_i"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0894"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_epoch(model):\n",
    "  accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
    "  return round(torch.stack(accs).mean().item(),4)\n",
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7g9PpvMoWgVV",
    "outputId": "7c640ac0-52ca-4beb-ef6d-e389439f27ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0917"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One example \n",
    "lr = 1.\n",
    "params = weights,bias\n",
    "train_epoch(linear1, lr, params)\n",
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lbJgoKYNWsJR",
    "outputId": "d53ea436-1b29-4180-9497-c40a266ed7e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1467 0.1561 0.1688 0.1811 0.1923 0.2051 0.2201 0.2297 0.2393 0.2501 0.2602 0.2716 0.2823 0.2925 0.3037 0.3123 0.3205 0.3284 0.3359 0.3418 "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "  train_epoch(linear1, lr, params)\n",
    "  print(validate_epoch(linear1), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, accuracy is improving, which means the model is learning! However, we want to improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXKTnDqbqdYD"
   },
   "source": [
    "## Creating an Optimizer\n",
    "\n",
    "We can create the same linear function we just built using PyTorc's `nn.Linear()` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xVCLaRtXW5L8",
    "outputId": "d8a0adc8-a51a-4019-8a8e-18923b9691f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 784]), torch.Size([10]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28,10)\n",
    "w,b = linear_model.parameters()\n",
    "w.shape,b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create an optimizer and a function to train one epoch using it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "_U8By3RxqpwW"
   },
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "  def __init__(self,params,lr): self.params,self.lr = list(params), lr\n",
    "  \n",
    "  def step(self, *args, **kwargs):\n",
    "    for p in self.params: p.data -= p.grad.data * self.lr\n",
    "\n",
    "  def zero_grad(self, *args, **kwargs):\n",
    "    for p in self.params: p.grad = None\n",
    "\n",
    "opt = BasicOptim(linear_model.parameters(), lr)\n",
    "\n",
    "def train_epoch(model):\n",
    "  for xb,yb in dl:\n",
    "    calc_grad(xb,yb,model)\n",
    "    opt.step()\n",
    "    opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8J58OcNOrXKL",
    "outputId": "2260cb2f-562d-4708-bd29-38a6fd2410a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1067"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "KgQJjvQhrhT1"
   },
   "outputs": [],
   "source": [
    "def train_model(model, epochs):\n",
    "  for i in range(epochs):\n",
    "    train_epoch(model)\n",
    "    print(validate_epoch(model), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rV7s3p_irpB5",
    "outputId": "0de6fe0f-5827-48ae-a8b3-63d872d1edc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1403 0.3382 0.2899 0.338 0.3849 0.4236 0.4773 0.5131 0.5325 0.552 0.5722 0.5906 0.6071 0.6213 0.6332 0.6451 0.6551 0.6643 0.6736 0.6809 "
     ]
    }
   ],
   "source": [
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `DataLoaders` class and building a `Learner` with the functions we defined before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "XCjjs2xprrMX"
   },
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl, valid_dl)\n",
    "learn = Learner(dls, nn.Linear(28*28,10), opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "w3uHoo0WtXvZ",
    "outputId": "c7102f18-ae13-47d0-ac77-3c7b001a525d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.157329</td>\n",
       "      <td>0.167066</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.105744</td>\n",
       "      <td>0.152815</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.068694</td>\n",
       "      <td>0.137599</td>\n",
       "      <td>0.334900</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.044959</td>\n",
       "      <td>0.120876</td>\n",
       "      <td>0.430500</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.038344</td>\n",
       "      <td>0.108376</td>\n",
       "      <td>0.493700</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.035399</td>\n",
       "      <td>0.100201</td>\n",
       "      <td>0.531700</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.033736</td>\n",
       "      <td>0.094040</td>\n",
       "      <td>0.558900</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.032681</td>\n",
       "      <td>0.088980</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.031943</td>\n",
       "      <td>0.084674</td>\n",
       "      <td>0.600900</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.031394</td>\n",
       "      <td>0.080926</td>\n",
       "      <td>0.618600</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.030970</td>\n",
       "      <td>0.077619</td>\n",
       "      <td>0.635600</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.030631</td>\n",
       "      <td>0.074675</td>\n",
       "      <td>0.649600</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.030349</td>\n",
       "      <td>0.072040</td>\n",
       "      <td>0.662100</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.030107</td>\n",
       "      <td>0.069672</td>\n",
       "      <td>0.674300</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.029893</td>\n",
       "      <td>0.067535</td>\n",
       "      <td>0.685600</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.029701</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.695100</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.029523</td>\n",
       "      <td>0.063841</td>\n",
       "      <td>0.704500</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.029357</td>\n",
       "      <td>0.062239</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.029193</td>\n",
       "      <td>0.060774</td>\n",
       "      <td>0.718300</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.059426</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(20,lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, accuracy is improving too. However, we can train a better model if we add a nonlinearity between our linear functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFgRZcvJJzsn"
   },
   "source": [
    "## Adding a non-linearity\n",
    "\n",
    "As we have 10 classes, the output layer must output 10 values as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "eCGAEL7-te1-"
   },
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,300),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(300,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now we build a learner for this simple net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "SGzcVWhVa4fj"
   },
   "outputs": [],
   "source": [
    "learn = Learner(dls, simple_net, opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_VJD8YFKbDf-",
    "outputId": "c2edb29f-de59-4b16-fabb-fbfa9684c4eb",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.181721</td>\n",
       "      <td>0.177023</td>\n",
       "      <td>0.440900</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.180410</td>\n",
       "      <td>0.170850</td>\n",
       "      <td>0.480100</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.176802</td>\n",
       "      <td>0.161541</td>\n",
       "      <td>0.441400</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.163254</td>\n",
       "      <td>0.150322</td>\n",
       "      <td>0.347700</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.136698</td>\n",
       "      <td>0.144714</td>\n",
       "      <td>0.323600</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.122496</td>\n",
       "      <td>0.131697</td>\n",
       "      <td>0.387900</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.118309</td>\n",
       "      <td>0.120395</td>\n",
       "      <td>0.445700</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.118121</td>\n",
       "      <td>0.111767</td>\n",
       "      <td>0.470900</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.114683</td>\n",
       "      <td>0.105283</td>\n",
       "      <td>0.492100</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.105525</td>\n",
       "      <td>0.100959</td>\n",
       "      <td>0.513400</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.098211</td>\n",
       "      <td>0.096996</td>\n",
       "      <td>0.533700</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.093368</td>\n",
       "      <td>0.093213</td>\n",
       "      <td>0.552100</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.089923</td>\n",
       "      <td>0.089774</td>\n",
       "      <td>0.568400</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.087287</td>\n",
       "      <td>0.086707</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.085186</td>\n",
       "      <td>0.083964</td>\n",
       "      <td>0.597000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.083463</td>\n",
       "      <td>0.081499</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.082019</td>\n",
       "      <td>0.079268</td>\n",
       "      <td>0.623700</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.080787</td>\n",
       "      <td>0.077239</td>\n",
       "      <td>0.632800</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.079723</td>\n",
       "      <td>0.075388</td>\n",
       "      <td>0.640200</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.078797</td>\n",
       "      <td>0.073691</td>\n",
       "      <td>0.648600</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.077982</td>\n",
       "      <td>0.072133</td>\n",
       "      <td>0.657900</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.077261</td>\n",
       "      <td>0.070702</td>\n",
       "      <td>0.665800</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.076619</td>\n",
       "      <td>0.069385</td>\n",
       "      <td>0.674200</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.076045</td>\n",
       "      <td>0.068174</td>\n",
       "      <td>0.681300</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.075529</td>\n",
       "      <td>0.067060</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.075062</td>\n",
       "      <td>0.066032</td>\n",
       "      <td>0.692200</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.074638</td>\n",
       "      <td>0.065082</td>\n",
       "      <td>0.696800</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.074249</td>\n",
       "      <td>0.064204</td>\n",
       "      <td>0.700300</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.073888</td>\n",
       "      <td>0.063390</td>\n",
       "      <td>0.703800</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.073549</td>\n",
       "      <td>0.062633</td>\n",
       "      <td>0.707600</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.073221</td>\n",
       "      <td>0.061925</td>\n",
       "      <td>0.711100</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.072886</td>\n",
       "      <td>0.061258</td>\n",
       "      <td>0.714100</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.072501</td>\n",
       "      <td>0.060613</td>\n",
       "      <td>0.716800</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.071896</td>\n",
       "      <td>0.059912</td>\n",
       "      <td>0.718600</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.068663</td>\n",
       "      <td>0.056409</td>\n",
       "      <td>0.738600</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.041185</td>\n",
       "      <td>0.058221</td>\n",
       "      <td>0.748900</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.037020</td>\n",
       "      <td>0.057849</td>\n",
       "      <td>0.748500</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.036197</td>\n",
       "      <td>0.056785</td>\n",
       "      <td>0.751700</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.035586</td>\n",
       "      <td>0.055744</td>\n",
       "      <td>0.755200</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.035081</td>\n",
       "      <td>0.054723</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(40,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy improved! Now we understand how to build a Learner from scratch. We can leverage fastai's library to build a more robust model with just a couple lines of code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More robust model\n",
    "\n",
    "We will use the `ImageDataLoaders` class, and set the device to 'mps' to leverage the power of the Apple Sillicon GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-FQ5yVx1bFKl",
    "outputId": "81eba72f-7901-4b3f-e386-d2c56e887dfd"
   },
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_folder(path, train='training', valid='testing', device='mps')\n",
    "learn = vision_learner(dls, resnet18, pretrained=False, loss_func=F.cross_entropy, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 94
    },
    "id": "G5wbzLrobdhM",
    "outputId": "3c7408fc-f2f8-4495-d692-bb9b26598820",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.045411</td>\n",
       "      <td>0.988100</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the resnet18 neural net achieves >98% accuracy in just one epoch!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
